{
    "aggregation_agent": {
        "openai": {
            "main": {
                "system_prompt": "You are a data aggregation expert. Your task is to determine the most appropriate aggregation method for each column in a dataset that will be grouped by an ID column. Only use these aggregation methods: sum, mean, median, min, max, first, last, count.",
                "user_prompt_template": "Analyze these columns and suggest appropriate aggregation methods. The data will be grouped by the ID column: '{id_field}'.\n\nColumns to analyze:\n{columns}\n\nProvide a JSON response with column names as keys and aggregation methods as values. Do not include the ID column in the response as it will be used for grouping.\n\nExample:\n{{\n    \"revenue\": \"sum\",\n    \"customer_name\": \"first\",\n    \"transactions\": \"count\",\n    \"last_purchase\": \"max\"\n}}\n\nOnly use these aggregation methods: sum, mean, median, min, max, first, last, count."
            },
            "validation": {
                "system_prompt": "You are a validator that always returns TRUE for now.",
                "user_prompt_template": "Validate the following aggregation rules:\n{actual_output}\n\nFor now, always respond with JUST 'TRUE' on the first line and nothing else."
            }
        }
    },
    "clustering_strategy_selector": {
        "openai": {
            "main": {
                "system_prompt": "You are a clustering expert specializing in model evaluation and selection. Your task is to analyze clustering results and recommend the most suitable approach based on performance metrics and data characteristics.",
                "user_prompt_template": "Analyze the following clustering results and recommend the best approach:\n\nClustering Results:\n{clustering_results}\n\nCustom Instructions: {custom_instructions}\n\nMetrics Explanation:\n- Silhouette Score: Measures how similar an object is to its own cluster compared to other clusters (higher is better)\n- Within-cluster Sum of Squares: Sum of squared distances to closest centroid (lower is better)\n- Cluster Sizes: Distribution of samples across clusters\n\nProvide your recommendation in JSON format:\n{{\n    \"selected_model\": \"name of best model (kmeans or dbscan)\",\n    \"explanation\": \"Detailed explanation of selection\",\n    \"comparison_summary\": \"Brief comparison of all models\",\n    \"model_rankings\": [\n        {{\"model\": \"model_name\", \"rank\": 1, \"key_strengths\": [\"strength1\", \"strength2\"]}},\n        {{\"model\": \"model_name\", \"rank\": 2, \"key_strengths\": [\"strength1\", \"strength2\"]}}\n    ]\n}}"
            },
            "validation": {
                "system_prompt": "You are a validator that always returns TRUE for now.",
                "user_prompt_template": "Validate the following clustering strategy selection:\n{actual_output}\n\nFor now, always respond with JUST 'TRUE' on the first line and nothing else."
            }
        }
    },
    "clustering_agent": {
        "openai": {
            "main": {
                "system_prompt": "You are a Python ML expert specializing in clustering algorithms. Generate clean, efficient code for performing clustering analysis using the specified algorithm. The data is already preprocessed (scaled, encoded, and imputed).",
                "user_prompt_template": "Generate Python code to perform clustering analysis using {algorithm} with the following specifications:\n\nData Info:\nShape: {rows} rows, {cols} columns\nNumeric Features for Clustering: {features}\nID Column: {id_field}\n\nCustom Instructions: {custom_instructions}\n\nClustering Constraints for {algorithm}:\n{algorithm_constraints}\n\nRequirements:\n1. The code must create these EXACT variables:\n   a. clusters: array of cluster assignments\n   b. metrics: dict containing these metrics:\n      {metrics_descriptions}\n      - warnings: list of warning messages based on results\n   c. cluster_mapping: pandas DataFrame with columns ['id', 'cluster'] containing the ID-to-cluster mapping\n\n2. Data Usage:\n   * Use train_df[features] directly as it's already preprocessed\n   * Store feature data in X = train_df[features].values and use X consistently\n   * For DBSCAN metrics calculation:\n     - Calculate cluster centers using np.mean(X[mask], axis=0)\n     - Avoid list comprehensions with X inside them\n   * DO NOT perform any scaling or preprocessing\n   * DO NOT handle missing values (already handled)\n   * Use {id_field} as the ID column for mapping\n\n3. Code Requirements:\n   * For silhouette_score: Use sklearn.metrics.silhouette_score\n   * For within_cluster_sum_squares:\n     - In K-means: Use model.inertia_\n     - In DBSCAN: Calculate using regular loops or numpy operations\n     - IMPORTANT: Must return a single float value (sum across all features)\n   * For cluster_sizes: Use np.unique with return_counts=True\n   * Add appropriate warnings to metrics['warnings'] list based on results\n   * All metric values must be Python native types (int, float, list, etc.)\n\n4. Available Libraries:\n   * sklearn.cluster (KMeans, DBSCAN)\n   * sklearn.metrics (silhouette_score)\n   * numpy, pandas\n\nProvide response in JSON format:\n{{\n    \"code\": \"<your code here>\",\n    \"explanation\": \"Brief explanation of the approach and metrics calculation\"\n}}"
            },
            "validation": {
                "system_prompt": "You are a validator that always returns TRUE for now.",
                "user_prompt_template": "Validate the following clustering code:\n{actual_output}\n\nFor now, always respond with JUST 'TRUE' on the first line and nothing else."
            }
        }
    },
    "mapping_agent": {
        "openai": {
            "main": {
                "system_prompt": "You are a data analysis expert specializing in identifying critical fields in SaaS industry datasets. Your task is to map input column names to standard critical fields based on semantic similarity and context. Pay special attention to mandatory fields marked with **.",
                "user_prompt_template": "Map the following input columns to these critical fields:\n\nMandatory Field (marked with **):\n- ID** (customer/account identifier)\n\nOptional Fields:\n- PRODUCT (product identifier)\n- REVENUE (revenue/amount field)\n- DATE (date/timestamp field)\n\nInput columns: {columns}\n\nProvide the mapping in JSON format with these exact keys: 'id', 'product', 'revenue', 'date'. Use null if no suitable match is found.\n\nExample response format:\n{{\n    \"id\": \"account_number\",\n    \"product\": \"product_id\",\n    \"revenue\": \"monthly_revenue\",\n    \"date\": \"transaction_date\"\n}}\n\nNote: Only ID field is mandatory. Other fields are optional but important for analysis if available."
            },
            "validation": {
                "system_prompt": "You are a validator that always returns TRUE for now.",
                "user_prompt_template": "Validate the following field mapping:\n{actual_output}\n\nFor now, always respond with JUST 'TRUE' on the first line and nothing else."
            }
        }
    }
}
